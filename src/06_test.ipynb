{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Formação Cientista de Dados\n",
    "### Projeto com Feedback 4\n",
    "### Prevendo Customer Churn em Operadoras de Telecom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gabriel Quaiotti - Abr 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Customer Churn (ou Rotatividade de Clientes, em uma tradução livre) refere-se a uma decisão tomada pelo cliente sobre o término do relacionamento comercial. Refere-se também à perda de clientes. A fidelidade do cliente e a rotatividade de clientes sempre somam 100%. Se uma empresa tem uma taxa de fidelidade de 60%, então a taxa de perda de clientes é de 40%. De acordo com a\n",
    "regra de lucratividade do cliente 80/20, 20% dos clientes estão gerando 80% da receita. Portanto, é muito importante prever os usuários que provavelmente abandonarão o relacionamento comercial e os fatores que afetam as decisões do cliente.\n",
    "\n",
    "Neste projeto, você deve prever o Customer Churn em uma Operadora de Telecom.\n",
    "\n",
    "Os datasets de treino e de teste serão fornecidos para você em anexo a este projeto. Seu trabalho é criar um modelo de aprendizagem de máquina que possa prever se um cliente pode ou não cancelar seu plano e qual a probabilidade\n",
    "de isso ocorrer. O cabeçalho do dataset é uma descrição do tipo de informação em cada coluna.\n",
    "\n",
    "Usando linguagem Python, recomendamos você criar um modelo de Regressão Logística, para extrair a informação se um cliente vai cancelar seu plano (Sim ou Não) e a probabilidade de uma opção ou outra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "from pyspark.sql.types import StructType\n",
    "from pyspark.sql.types import StructField\n",
    "from pyspark.sql.types import StringType\n",
    "from pyspark.sql.types import DoubleType\n",
    "from pyspark.sql.types import IntegerType\n",
    "\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.functions import regexp_replace\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.functions import stddev\n",
    "from pyspark.sql.functions import mean\n",
    "\n",
    "from pyspark.ml.feature import MinMaxScaler\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.pipeline import PipelineModel\n",
    "\n",
    "\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.classification import LogisticRegressionModel\n",
    "\n",
    "\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spark Session - usado para trabalhar com o Spark\n",
    "spSession = SparkSession.builder.master(\"local\").appName(\"DSA-TELECOM-TEST\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load TEST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read train dataset\n",
    "features_rdd = sc.textFile('../data/projeto4_telecom_teste.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\"\",\"state\",\"account_length\",\"area_code\",\"international_plan\",\"voice_mail_plan\",\"number_vmail_messages\",\"total_day_minutes\",\"total_day_calls\",\"total_day_charge\",\"total_eve_minutes\",\"total_eve_calls\",\"total_eve_charge\",\"total_night_minutes\",\"total_night_calls\",\"total_night_charge\",\"total_intl_minutes\",\"total_intl_calls\",\"total_intl_charge\",\"number_customer_service_calls\",\"churn\"',\n",
       " '\"1\",\"HI\",101,\"area_code_510\",\"no\",\"no\",0,70.9,123,12.05,211.9,73,18.01,236,73,10.62,10.6,3,2.86,3,\"no\"',\n",
       " '\"2\",\"MT\",137,\"area_code_510\",\"no\",\"no\",0,223.6,86,38.01,244.8,139,20.81,94.2,81,4.24,9.5,7,2.57,0,\"no\"',\n",
       " '\"3\",\"OH\",103,\"area_code_408\",\"no\",\"yes\",29,294.7,95,50.1,237.3,105,20.17,300.3,127,13.51,13.7,6,3.7,1,\"no\"',\n",
       " '\"4\",\"NM\",99,\"area_code_415\",\"no\",\"no\",0,216.8,123,36.86,126.4,88,10.74,220.6,82,9.93,15.7,2,4.24,1,\"no\"']"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_rdd.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove header and split by ','\n",
    "header = features_rdd.first()\n",
    "features_rdd2 = features_rdd.filter(lambda line: line != header).map(lambda line: line.split(\",\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the dataFrame columns\n",
    "test_fields = [StructField(\"id\", StringType(), True), \n",
    "     StructField(\"state\", StringType(), True),\n",
    "     StructField(\"account_length\", StringType(), True),\n",
    "     StructField(\"area_code\", StringType(), True),\n",
    "     StructField(\"international_plan\", StringType(), True),\n",
    "     StructField(\"voice_mail_plan\", StringType(), True),\n",
    "     StructField(\"number_vmail_messages\", StringType(), True),\n",
    "     StructField(\"total_day_minutes\", StringType(), True),\n",
    "     StructField(\"total_day_calls\", StringType(), True),\n",
    "     StructField(\"total_day_charge\", StringType(), True),\n",
    "     StructField(\"total_eve_minutes\", StringType(), True),\n",
    "     StructField(\"total_eve_calls\", StringType(), True),\n",
    "     StructField(\"total_eve_charge\", StringType(), True),\n",
    "     StructField(\"total_night_minutes\", StringType(), True),\n",
    "     StructField(\"total_night_calls\", StringType(), True),\n",
    "     StructField(\"total_night_charge\", StringType(), True),\n",
    "     StructField(\"total_intl_minutes\", StringType(), True),\n",
    "     StructField(\"total_intl_calls\", StringType(), True),\n",
    "     StructField(\"total_intl_charge\", StringType(), True),\n",
    "     StructField(\"number_customer_service_calls\", StringType(), True),\n",
    "     StructField(\"churn\", StringType(), True)]     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the dataFrame schema\n",
    "features_schema = StructType( test_fields )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataFrame\n",
    "test_ds = spSession.createDataFrame(features_rdd2, features_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds = test_ds.select('international_plan', 'number_customer_service_calls', 'total_day_minutes', 'total_eve_charge', 'churn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace values into String columns\n",
    "test_ds = test_ds.withColumn('international_plan', regexp_replace(col('international_plan'), 'no', '0') )\n",
    "test_ds = test_ds.withColumn('international_plan', regexp_replace(col('international_plan'), 'yes', '1') )\n",
    "test_ds = test_ds.withColumn('international_plan', regexp_replace(col('international_plan'), '\"', '') )\n",
    "\n",
    "test_ds = test_ds.withColumn('churn', regexp_replace(col('churn'), 'no', '0') )\n",
    "test_ds = test_ds.withColumn('churn', regexp_replace(col('churn'), 'yes', '1') )\n",
    "test_ds = test_ds.withColumn('churn', regexp_replace(col('churn'), '\"', '') )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cast column types to Int or Double\n",
    "test_ds = test_ds.withColumn(\"total_day_minutes\", test_ds[\"total_day_minutes\"].cast(DoubleType()))\n",
    "test_ds = test_ds.withColumn(\"total_eve_charge\", test_ds[\"total_eve_charge\"].cast(DoubleType()))\n",
    "test_ds = test_ds.withColumn(\"number_customer_service_calls\", test_ds[\"number_customer_service_calls\"].cast(DoubleType()))\n",
    "test_ds = test_ds.withColumn(\"international_plan\", test_ds[\"international_plan\"].cast(DoubleType()))\n",
    "test_ds = test_ds.withColumn(\"churn\", test_ds[\"churn\"].cast(DoubleType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>international_plan</th>\n",
       "      <th>number_customer_service_calls</th>\n",
       "      <th>total_day_minutes</th>\n",
       "      <th>total_eve_charge</th>\n",
       "      <th>churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>70.9</td>\n",
       "      <td>18.01</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>223.6</td>\n",
       "      <td>20.81</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>294.7</td>\n",
       "      <td>20.17</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>216.8</td>\n",
       "      <td>10.74</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>197.4</td>\n",
       "      <td>10.54</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   international_plan  number_customer_service_calls  total_day_minutes  \\\n",
       "0                 0.0                            3.0               70.9   \n",
       "1                 0.0                            0.0              223.6   \n",
       "2                 0.0                            1.0              294.7   \n",
       "3                 0.0                            1.0              216.8   \n",
       "4                 0.0                            2.0              197.4   \n",
       "\n",
       "   total_eve_charge  churn  \n",
       "0             18.01    0.0  \n",
       "1             20.81    0.0  \n",
       "2             20.17    0.0  \n",
       "3             10.74    0.0  \n",
       "4             10.54    0.0  "
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ds.toPandas().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform features to vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert predictor columns to vector\n",
    "vector_ds = VectorAssembler(inputCols = test_ds.drop('churn').columns, outputCol=\"features\").transform(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[international_plan: double, number_customer_service_calls: double, total_day_minutes: double, total_eve_charge: double, churn: double, features: vector]"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scale TEST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the columns to scale (predictors)\n",
    "columns_to_scale = test_ds.drop('churn').columns\n",
    "\n",
    "# Transform values to vector (requirement)\n",
    "assemblers = [VectorAssembler(inputCols=[col], outputCol=col + \"_vec\") for col in columns_to_scale]\n",
    "\n",
    "# Scale column values\n",
    "scalers = [MinMaxScaler(inputCol=col + \"_vec\", outputCol=col + \"_scaled\") for col in columns_to_scale]\n",
    "\n",
    "# Execute the pipeline (Vector + Scale)\n",
    "pipeline = Pipeline(stages=assemblers + scalers)\n",
    "\n",
    "# Fit the scale model\n",
    "scalerModel = pipeline.fit(test_ds)\n",
    "\n",
    "# Transform as dataFrame\n",
    "scaled_ds = scalerModel.transform(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform vector to double\n",
    "unlist = udf(lambda x: float(list(x)[0]), DoubleType())\n",
    "\n",
    "# Get scaled values\n",
    "for i in columns_to_scale:\n",
    "    # Transform original column\n",
    "    scaled_ds = scaled_ds.withColumn(i, unlist(i + \"_scaled\"))\n",
    "    # Drop _vec column\n",
    "    scaled_ds = scaled_ds.drop(i + \"_vec\")\n",
    "    # Drop _scaled column\n",
    "    scaled_ds = scaled_ds.drop(i + \"_scaled\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standartize TEST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['international_plan',\n",
       " 'number_customer_service_calls',\n",
       " 'total_day_minutes',\n",
       " 'total_eve_charge']"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the columns to scale (predictors)\n",
    "columns_to_standard = scaled_ds.drop('id', 'churn').columns\n",
    "columns_to_standard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in columns_to_standard:\n",
    "    m = scaled_ds.select(mean(i).alias('mean')).collect()\n",
    "    s = scaled_ds.select(stddev(i).alias('std')).collect()\n",
    "    scaled_ds = scaled_ds.withColumn(i, (col(i) - m[0]['mean']) / s[0]['std'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert predictor columns to vector\n",
    "vector_ds = VectorAssembler(inputCols=scaled_ds.drop('churn').columns, outputCol=\"features\").transform(scaled_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------------------------+--------------------+--------------------+-----+--------------------+\n",
      "|  international_plan|number_customer_service_calls|   total_day_minutes|    total_eve_charge|churn|            features|\n",
      "+--------------------+-----------------------------+--------------------+--------------------+-----+--------------------+\n",
      "|-0.31435656731631717|           1.0980750080169768| -2.0939056396184457|  0.2375069325583213|  0.0|[-0.3143565673163...|\n",
      "|-0.31435656731631717|           -1.230793997535554|  0.8018596606739083|  0.8932817674646958|  0.0|[-0.3143565673163...|\n",
      "|-0.31435656731631717|          -0.4545043290180438|  2.1501826001027644|  0.7433903766289537|  0.0|[-0.3143565673163...|\n",
      "|-0.31435656731631717|          -0.4545043290180438|  0.6729061306019508| -1.4651655852164471|  0.0|[-0.3143565673163...|\n",
      "|-0.31435656731631717|          0.32178533949946647|  0.3050092948084224| -1.5120066448526168|  0.0|[-0.3143565673163...|\n",
      "|-0.31435656731631717|          -0.4545043290180438|  0.8568545484987142| -1.1606986975813445|  0.0|[-0.3143565673163...|\n",
      "|-0.31435656731631717|          -0.4545043290180438|  0.7127300148888788|  0.2866900451762984|  0.0|[-0.3143565673163...|\n",
      "|-0.31435656731631717|           -1.230793997535554| -0.4516445066432141|  0.4881066016118283|  0.0|[-0.3143565673163...|\n",
      "|-0.31435656731631717|          0.32178533949946647| -1.7487653091317343|  -1.455797373289213|  0.0|[-0.3143565673163...|\n",
      "|-0.31435656731631717|           -1.230793997535554| -0.0666802918695743|  -1.048280154454537|  0.0|[-0.3143565673163...|\n",
      "|-0.31435656731631717|          -0.4545043290180438|  0.5401598496455227|  -0.713366578055924|  0.0|[-0.3143565673163...|\n",
      "|-0.31435656731631717|          -0.4545043290180438| -1.6710139160001125|-0.04588147824050621|  0.0|[-0.3143565673163...|\n",
      "|-0.31435656731631717|          -0.4545043290180438|  0.8871965555744687| -0.8749682338007092|  0.0|[-0.3143565673163...|\n",
      "|-0.31435656731631717|           1.0980750080169768|  -1.303117080206585| -1.6923447244518701|  0.0|[-0.3143565673163...|\n",
      "|-0.31435656731631717|          -0.4545043290180438| 0.49275046358965574| 0.15787713117683216|  0.0|[-0.3143565673163...|\n",
      "|-0.31435656731631717|          -0.4545043290180438|  0.5079214671275329|-0.21450929293071738|  0.0|[-0.3143565673163...|\n",
      "|-0.31435656731631717|          -0.4545043290180438| -1.2993243293221155|  0.6497082573566135|  0.0|[-0.3143565673163...|\n",
      "|-0.31435656731631717|          -0.4545043290180438|  0.8340980431918981|  0.5583681910660826|  0.0|[-0.3143565673163...|\n",
      "|-0.31435656731631717|           1.8743646765344872|-0.22597582901728736|  0.8066258071377826|  0.0|[-0.3143565673163...|\n",
      "|-0.31435656731631717|          -0.4545043290180438| 0.22725790167680102| 0.16256123714044918|  0.0|[-0.3143565673163...|\n",
      "+--------------------+-----------------------------+--------------------+--------------------+-----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vector_ds.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegressionModel.load(\"../obj/logistic_regression.obj\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.transform(vector_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>international_plan</th>\n",
       "      <th>number_customer_service_calls</th>\n",
       "      <th>total_day_minutes</th>\n",
       "      <th>total_eve_charge</th>\n",
       "      <th>churn</th>\n",
       "      <th>features</th>\n",
       "      <th>rawPrediction</th>\n",
       "      <th>probability</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.314357</td>\n",
       "      <td>1.098075</td>\n",
       "      <td>-2.093906</td>\n",
       "      <td>0.237507</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[-0.31435656731631717, 1.0980750080169768, -2....</td>\n",
       "      <td>[0.7504101832107734, -0.7504101832107734]</td>\n",
       "      <td>[0.6792680694739247, 0.3207319305260753]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.314357</td>\n",
       "      <td>-1.230794</td>\n",
       "      <td>0.801860</td>\n",
       "      <td>0.893282</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[-0.31435656731631717, -1.230793997535554, 0.8...</td>\n",
       "      <td>[0.6884941765504509, -0.6884941765504509]</td>\n",
       "      <td>[0.665631865153395, 0.33436813484660494]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.314357</td>\n",
       "      <td>-0.454504</td>\n",
       "      <td>2.150183</td>\n",
       "      <td>0.743390</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[-0.31435656731631717, -0.4545043290180438, 2....</td>\n",
       "      <td>[-1.076142456507508, 1.076142456507508]</td>\n",
       "      <td>[0.2542367148420343, 0.7457632851579656]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.314357</td>\n",
       "      <td>-0.454504</td>\n",
       "      <td>0.672906</td>\n",
       "      <td>-1.465166</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[-0.31435656731631717, -0.4545043290180438, 0....</td>\n",
       "      <td>[0.4650273424971406, -0.4650273424971406]</td>\n",
       "      <td>[0.6142061217921756, 0.3857938782078244]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.314357</td>\n",
       "      <td>0.321785</td>\n",
       "      <td>0.305009</td>\n",
       "      <td>-1.512007</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[-0.31435656731631717, 0.32178533949946647, 0....</td>\n",
       "      <td>[-0.003832589247174896, 0.003832589247174896]</td>\n",
       "      <td>[0.49904185386103594, 0.500958146138964]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   international_plan  number_customer_service_calls  total_day_minutes  \\\n",
       "0           -0.314357                       1.098075          -2.093906   \n",
       "1           -0.314357                      -1.230794           0.801860   \n",
       "2           -0.314357                      -0.454504           2.150183   \n",
       "3           -0.314357                      -0.454504           0.672906   \n",
       "4           -0.314357                       0.321785           0.305009   \n",
       "\n",
       "   total_eve_charge  churn                                           features  \\\n",
       "0          0.237507    0.0  [-0.31435656731631717, 1.0980750080169768, -2....   \n",
       "1          0.893282    0.0  [-0.31435656731631717, -1.230793997535554, 0.8...   \n",
       "2          0.743390    0.0  [-0.31435656731631717, -0.4545043290180438, 2....   \n",
       "3         -1.465166    0.0  [-0.31435656731631717, -0.4545043290180438, 0....   \n",
       "4         -1.512007    0.0  [-0.31435656731631717, 0.32178533949946647, 0....   \n",
       "\n",
       "                                   rawPrediction  \\\n",
       "0      [0.7504101832107734, -0.7504101832107734]   \n",
       "1      [0.6884941765504509, -0.6884941765504509]   \n",
       "2        [-1.076142456507508, 1.076142456507508]   \n",
       "3      [0.4650273424971406, -0.4650273424971406]   \n",
       "4  [-0.003832589247174896, 0.003832589247174896]   \n",
       "\n",
       "                                probability  prediction  \n",
       "0  [0.6792680694739247, 0.3207319305260753]         0.0  \n",
       "1  [0.665631865153395, 0.33436813484660494]         0.0  \n",
       "2  [0.2542367148420343, 0.7457632851579656]         1.0  \n",
       "3  [0.6142061217921756, 0.3857938782078244]         0.0  \n",
       "4  [0.49904185386103594, 0.500958146138964]         1.0  "
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.toPandas().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EVALUATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "areaUnderROC 0.8197888822888871\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model\n",
    "evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\", labelCol = \"churn\")\n",
    "print(evaluator.getMetricName(), evaluator.evaluate(prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+-----+--------------------+\n",
      "|churn|prediction|count|                   %|\n",
      "+-----+----------+-----+--------------------+\n",
      "|  1.0|       1.0|  196| 0.11757648470305938|\n",
      "|  0.0|       1.0|  543| 0.32573485302939414|\n",
      "|  1.0|       0.0|   28|0.016796640671865627|\n",
      "|  0.0|       0.0|  900|  0.5398920215956808|\n",
      "+-----+----------+-----+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# View confusion matrix\n",
    "total = prediction.count()\n",
    "prediction.groupBy('churn', 'prediction').count().withColumn('%', col('count') / total).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = prediction.select('churn', 'prediction').withColumnRenamed('churn', 'label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = MulticlassMetrics(preds.rdd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6574685062987402"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[900.,  28.],\n",
       "       [543., 196.]])"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusionMatrix().toArray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
